---
title             : "Relation between OER adoption and persistence in higher education"
shorttitle        : ""

author: 
  - name          : "Debshila Basu Mallick"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "debshila@rice.edu"
  - name          : "Phillip J. Grimaldi"
    affiliation   : "1"
  - name          : "Jason Whittle"
    affiliation   : "2"
  - name          : "Andrew J. Waters"
    affiliation   : "1"
  - name          : "Ted Moore"
    affiliation   : "2"
  - name          : "Richard Baraniuk"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "OpenStax, Rice University"
  - id            : "2"
    institution   : "Salt Lake Community College"

author_note: |
  Cognitive Science Postdoctoral Research Associate, OpenStax, Rice University.
  Director of Research, OpenStax, Rice University.

  Enter author note here.

abstract: |
  A major problem currently facing education in America is the rising cost of obtaining a college degree. While tuition hikes predominate student costs, an additional source of expense is from textbook prices that have been found to rise at an alarming rate (134% increase since 2001; U.S. Bureau of Labor Statistics, 2016).

  In response to rising textbook costs, there has been a surge of interest in open educational resources (OER). OER differs from traditional education materials in that they are freely available. While OER has undoubtedly been successful at reducing student costs, the critical question is whether these cost savings translate into improved student academic outcomes. OER is presumed to help in this regard by improving access to beneficial learning materials, however research in this area is has found equivocal results (Hilton, 2016). While some studies found that adoption of open textbooks resulted in positive academic outcomes (Lovett et al., 2008), others have found no effect (Hilton et al., 2013), or a negative effect (Lawrence & Lester, 2018). The overarching goal of this project is to explore how adoption of an open textbook affects student academic outcomes.

  We examined the effect of transitioning from a conventional textbook to an open textbook for all sections of a required course at the Salt Lake Community College (SLCC). This was a unique opportunity to examine the impact of open textbook use because this large scale adoption was institutionally mandated, which implied that, unlike other situations where instructors generally opt in to adopt an open textbook for their own course, all instructors were required to use the same textbook for the course removing any concerns of self-selection bias. 

  In collaboration with SLCC, we acquired student academic outcomes before and after transition to the open textbook, demographic, prior achievement, and other parameters related to the course. We attempted to ensure that any possible changes in the outcomes were primarily due to the open textbook adoption and not due to any temporal factors that naturally permeated across other comparable disciplines. In order to rule out other temporal confounds, we contrasted academic outcomes in the history course with other comparable disciplines, which continued to exclusively use traditional textbooks during the same period.

  Preliminary results indicate that there was no positive effect of open textbook adoption on the number of students passing the course. Further analyses are underway, and the findings will be discussed in light of expectations surrounding OER efficacy, and integration of OER into a course curriculum.

  
keywords          : "OER, Persistence, Higher Education"
wordcount         : "X"

bibliography      : ["r-references.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no
fig.cap           : yes
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
library("papaja")
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

```{r setup, echo=FALSE, warning=FALSE, message=FALSE, comment=""}
# Source supporting files
source("~/Documents/oer-history/supportingScripts/SLCC History 2011-2018.R")
source("~/Documents/oer-history/supportingScripts/SLCC Plot Functions.R")
SLCC_11_18_proc <- SLCC_11_18_proc  %>% 
  mutate(oer = factor(oer)) %>% 
  ungroup()
```

** NOTES:MAKE OVERALL PLOT for pass rate and grade; lsmeans, do correlation plot**
The face of a typical American classroom is changing due to various socio-economic-technological factors. One of these factors is the rise in the cost of higher education in the United States. A glaring example of the the rise in the cost of higher ed in the US are the student debt levels reaching a staggering 1.3 billion dollars (Federal Reserve Bank of New York, 2016). While tuition hikes 

A major problem currently facing education in America is the rising cost of obtaining a college degree. Indeed, in 2016 student debt levels reached an all time high of 1.3 trillion dollars (Federal Reserve Bank of New York, 2016). While tuition hikes can account for a large portion of student costs, an additional source of cost increases come from rising textbook prices.  According to the U.S Bureau of Labor Statistics (2016), textbook costs have increased 134% from what they were in 2001. In fact, textbook prices are increasing at a faster rate than health care (U.S. Bureau of Labor Statistics, 2016).  According to the College Board (2016), students spend an average of $1280 on textbooks annually. In sum, textbooks represent a large chunk of the costs involved in obtaining a college degree, and the problem is only getting worse.   

In response to rising textbook costs, there has been a surge of interest in open educational resources (OER). OER differs from traditional education materials in that they are freely available, and usually easily accessible online. The OER movement in education has not only impacted the US but has had a widespread global influence [@Farrow2015].

<!--Since 2012, OpenStax has been a leader in the OER movement, providing a large library of free, high-quality, open-source textbooks. OpenStax currently offers 27 intro level textbooks, which have been used in nearly 30% of all degree granting institutions in the United States. Over 1 million students have used an OpenStax books to date, saving students an estimated $35 million. Importantly, growth in the use of OpenStax texts has been exponential-- the estimated cost savings to date are expected to double in 2017.-->

While OpenStax has been undoubtedly successful at reducing student costs, the critical question is whether these cost savings translate into improved student success. OER is presumed to help in this regard by improving access to beneficial learning materials, however research in this area is sparse. The overarching goal of this project is to explore how adoption of an OpenStax textbook affects student success, with special attention paid to low-income students.     

Existing research suggests that high textbook costs have a negative impact on academic success. A recent survey found that an alarming proportion of students have dropped (27%) or withdrew (21%) from a course due to the cost of textbooks (Florida Virtual Campus, 2012). Worse, this same survey found that nearly 44% of students report that they earned a poor grade because they could not afford the textbook. We hypothesize that adopting a free OpenStax book will a) increase course completion, b) increase pass rates, and c) improve final grades. 

To address the issue of examining efficacy of OER in persistence of higher education, we collaborated with Salt Lake Community Collge who initiated adoption of OpenStax History in their require Introductory History course.

#### Interaction between online courses and adoption of OER



# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Material

## Procedure

**The authors collected the following datapoints for the history course at SLCC recorded 8 semesters prior to (Fall, 2011), and 9 semesters following (Spring, 2017) the transition to OER** :   

* _course metadata_ (e.g., instructor id, course number, section id, term start and end dates)       
* _student demographics_ (e.g., ethnicity, gender, pell eligibility, enrolment status)        
* _academic background_ (e.g., cumulative undergraduate GPA, prior achievement scores such as college placement test scores), and            
* _course performance_ (e.g., final course grade, credits earned)           

In addition, this dataset included the above parameters for 2 other courses (Political Science, Economics) that exclusively used conventional textbooks. Unlike other studies examining impact of OER on student performance, we used data from these 2 courses were used to tease apart any temporal fluctuations in student performance that occurred even without the use of OER. 

### History OER implementation

This section describes the implementation of the history OER textbook adoption based on course syllabi. Prior to the adoption of the history open textbook, [@foner2013give] was the textbook adopted by a majority of the introductory history course sections. Typical coursework varied across instructors, and typically included an assortment of readings, impact papers, examinations 2-6 in class examinations, take home exams.



Things to address here: difficulty of traditional textbook and oer content. Previous studies have failed to precisely detail the traditional and open textbooks used, and compare the difficulty of the traditional textbook and the oer content used [@Griggs2017]. There were XX traditional textbooks used 



## Participants

We had a total of `sCount` student records in the dataset. Out of these records, `r nrow(underAge)` students were less than 18 years of age when the term started and  were  therefore removed from further analyses. There were `r length(dupeIDs)` students who had more than one records in the dataset. These students may have either repeated a specific course, or taken courses in more than one course subjects included in this dataset, or both, resulting in an overall `r sum(duplicated(SLCC_11_18_proc$studentId), na.rm = TRUE)` additional records for these students. 

```{r pellElig}
pell <- SLCC_11_18_proc %>%
          distinct(studentId, .keep_all = TRUE) %>%
          count(everPellEligibleInd) %>% 
          mutate(pell = round(n/sum(n) * 100))
#          summarise(yes = round(sum(everPellEligibleInd == "Y")/n()*100), no = round(sum(everPellEligibleInd == "N")/n()*100))
```

```{r registration}
regStatus
```


```{r ethnicity, fig.cap="Ethnic diversity in the student population at SLCC."}
ethnicityCount
```
The dataset obtained from SLCC included `r n_distinct(SLCC_11_18_proc$studentId)` students (female =`r gender$n[1]`, male = `r gender$n[2]`, unreported = `r gender$n[3]`). Out of these students, `r pell$pell[pell$everPellEligibleInd == "Y"]`% were pell eligible, `r regStatus$enroll[regStatus$fullTime == "Full-Time"]`% were in full-time programs, and `r firstGen$firstgen[firstGen$firstGenerationInd == "Y"]`% identified as first generation students. 


## Data analysis

We examined the impact of OER adoption in terms of three different measures of student performance:  

* _Course completion:_ Based on whether students received any grade other than an "Incomplete" on the course.          

* _Pass rate:_ Based on whether students achieved "C-" or better in the course. If a student achieved a "C-" or better, then the student was considered to have passed (1) the class, whereas, if a student received a grade lower than a "C-", s/he was considered to have failed (0) the class.

* _Average grade:_ We also converted the student grades into a continuous measure that corresponded to the grade point (0-4) for the course.

We used `r cite_r("r-references.bib")` for all our analyses. 

# Results

## Course completion

Out of the `r nrow(SLCC_11_18_proc)` student records, only `r sum(SLCC_11_18_proc$finalGrade == "I")` cases had an incomplete grade. It must be pointed out that despite the small number of incomplete grades, these grades were only in the control courses (Economics, Political Science). Therefore, the current dataset did not present us with sufficient variability to examine differences in course completion rates across different conditions.


## Pass rates

We defined a grade above or equal to "C-" as a passing grade. Overall, out of our `r nrow(SLCC_11_18_proc)` records, `r sum(as.numeric(SLCC_11_18_proc$pass))` records showed a passing grade. 

```{r oer pass, fig.cap="Overall effect of OER on pass rates across different courses and semesters."}
passAggOer
```

```{r pass rate sem plot, fig.cap="Pass rates across textbook types, semesters, subject."}
passAggSemPlot
```

```{r pass rate, fig.cap="", fig.width=17, fig.height=5}
passLPlot
```

```{r pass rate pilot period, fig.cap="Difference in pass rate between courses using traditional and open textbooks over the pilot semesters."}
histPilotPassPlot
```

```{r pass treatment model} 
stargazer::stargazer(passM0, passM1, type = "text")
```

## Average grade

```{r grade line yrsem, fig.cap = "Average grade across academic semesters for each subject."}
agLPlot
```



```{r pass rate aggregate plot, fig.cap="Average grades across textbook types, semesters, subject."}
avgGradeAggPlt
```

```{r avg grade, fig.width=17, fig.height=5}
agLPlot
```

## Zoom in on those semester where there were both OER and traditional textbooks

```{r hist avg grade pilot period}
histAvgGrade
```

```{r grade base model}
```

```{r pass treatment model}
stargazer::stargazer(gradeM0, gradeM1, type = "text")
```

```{r grade interactive model}
# Interactive treatment model
gradeM2 <- SLCC_11_18_proc %>% 
  glmer(courseGrade ~ (1|courseSubject/instructorId) + (1|academicYear) + (1|semester) + everPellEligibleInd + fullTime + firstGenerationInd + cumUgGpa + onlineInd * oer, family = binomial, 
        control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
     optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)), data=.)

summary(courseGradeM2)

# Anova
gradeAnova2 <- anova(gradeM2)

gradeM2means <- emmeans(gradeM2, ~ oer * onlineInd)
emmip(gradeM2, onlineInd ~ oer)
# Plot random effects
gradeM2RE <- sjp.glmer(gradeM2, type = "re") + theme_minimal()
```

```{r grade model comparison}
AIC(gradeM0, passM1, passM2)
anova(passM1, passM2)
```



```{r grade treatment model}
# treatment model
gradeM1 <- SLCC_11_18_proc %>% 
  glmer(courseGrade ~ (1|courseSubject/instructorId) + (1|academicYear) + (1|semester) + onlineInd * oer, family = binomial, data=.)

# Find the least squares mean
gradePmmeans <- pmmeans(gradeM1, ~oer * onlineInd)

# Anova
gradeAnova <- anova(gradeM1)

# Model comparison
passComp <- anova(gradeM0, gradeM1)

# Plot random effects
gradeRE <- sjp.glmer(gradeM1, type = "re")

stargazer::stargazer(gradeM0, gradeM1, type = "text")
```

### Online vs. Classroom

```{r online/classroom and oer interaction}
passRateOnlinePlt 
```

```{r online/classroom and oer interaction}
avgGradeOnline
```


#### NEXT STEPS: lm with avg grade and pass rate, model with just history




# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
