---
title: "Persistence in higher education using Open Education Resources"
author: "The OpenStax Research Team, Salt Lake Community College"
date: '`r format(Sys.time(), "%B %d, %Y")`'
fontsize: 12pt
output: 
  pdf_document:
    fig_caption: yes
    keep_tex: no
    number_sections: yes
    toc: yes
font-family: 'Avenir'     
---
```{r globalOptios, echo=FALSE, warning=FALSE, message=FALSE, comment=""}
knitr::opts_chunk$set(fig.width=15, fig.height=20, fig.path='figures/', echo=FALSE, warning=FALSE, message=FALSE, fig.pos='center')
```

```{r setup, echo=FALSE, warning=FALSE, message=FALSE, comment=""}
source("~/Documents/git/oer-history/supportingScripts/SLCCpreProc.R")
```

# Introduction

A major problem currently facing education in America is the rising cost of obtaining a college degree. Indeed, in 2016 student debt levels reached an all time high of 1.3 trillion dollars (Federal Reserve Bank of New York, 2016). While tuition hikes can account for a large portion of student costs, an additional source of cost increases come from rising textbook prices.  According to the U.S Bureau of Labor Statistics (2016), textbook costs have increased 134% from what they were in 2001. In fact, textbook prices are increasing at a faster rate than health care (U.S. Bureau of Labor Statistics, 2016).  According to the College Board (2016), students spend an average of $1280 on textbooks annually. In sum, textbooks represent a large chunk of the costs involved in obtaining a college degree, and the problem is only getting worse.   

In response to rising textbook costs, there has been a surge of interest in open educational resources (OER). OER differs from traditional education materials in that they are freely available. Since 2012, OpenStax has been a leader in the OER movement, providing a large library of free, high-quality, open-source textbooks. OpenStax currently offers 27 intro level textbooks, which have been used in nearly 30% of all degree granting institutions in the United States. Over 1 million students have used an OpenStax books to date, saving students an estimated $35 million. Importantly, growth in the use of OpenStax texts has been exponential-- the estimated cost savings to date are expected to double in 2017.    

While OpenStax has been undoubtedly successful at reducing student costs, the critical question is whether these cost savings translate into improved student success. OER is presumed to help in this regard by improving access to beneficial learning materials, however research in this area is sparse. The overarching goal of this project is to explore how adoption of an OpenStax textbook affects student success, with special attention paid to low-income students.     

In this study we address two main questions:

* How does adoption of an OpenStax book affect course success?          
* Are the advantages of OpenStax adoption greater for low income students?         

## How does adoption of an OpenStax book affect course success?          

Existing research suggests that high textbook costs have a negative impact on academic success. A recent survey found that an alarming proportion of students have dropped (27%) or withdrew (21%) from a course due to the cost of textbooks (Florida Virtual Campus, 2012). Worse, this same survey found that nearly 44% of students report that they earned a poor grade because they could not afford the textbook. We hypothesize that adopting a free OpenStax book will a) reduce dropped classes, b) reduce withdrawn classes, and c) improve final grades. 

## Are the advantages of OpenStax adoption greater for low income students?     

High textbook costs are likely to have the biggest negative impact on socioeconomically disadvantaged students. Indeed, a recent survey of nearly 30,000 undergraduate students suggests that low income students are 1.61 times less likely to buy textbooks books than their middle and high income peers (Soria, Weiner & Lu, 2014). Thus, we hypothesize that the predicted positive effects of OpenStax adoption will be strongest with socioeconomically disadvantaged students.  

# Methods

This study will be conducted in collaboration with the Salt Lake Community College (SLCC). To date, over 23,840 students at SLCC have used an OpenStax textbook, saving these students over $2 million ??(Open Education Group & Utah Academic Libraries Consortium, 2016). Moreover, SLCC serves a diverse range of students, affording the evaluation of OER impact across students of varying backgrounds. Finally, SLCC's pre-existing research relationship with OpenStax has facilitated the data sharing process.

In the Summer 2014 (Winitzky-Stephens & Pickavance, 2017) all sections of the History course (Course ID # 1700) at SLCC switched from a conventional textbook to the OpenStax History textbook. This gave us a unique opportunity to examine the impact of transitioning from conventional to an open textbook on academic outcomes.      

## Data Collection

The authors collected the following datapoints for the history course recorded 8 semesters prior to (Fall, 2011), and 9 semesters following (Spring, 2017) the transition to OER :   
* course metadata (e.g., instructor id, course number, section id, term start and end dates) 
* student demographics (e.g., ethnicity, gender, pell eligibility, enrolment status)
* academic background (e.g., cumulative undergraduate GPA, prior achievement scores such as college placement test scores), and 
* course performance data (e.g., final course grade, credits earned) 

In addition, this dataset included the above parameters for 2 other courses (Political Science, Economics) that exclusibvely used conventional textbooks. Data from these 2 courses were used to tease apart any temporal fluctuations in student performance that occurred even without the use of OER. 

### Student Demographics

```{r gender}
gender <- SLCCpersistenceProc %>% 
  distinct(id, .keep_all = TRUE) %>% 
  count(gender)
```

```{r pellElig}
pell <- SLCCpersistenceProc %>% 
  distinct(id, .keep_all = TRUE) %>% 
  summarise(yes = round(sum(everPellEligibleInd == "Y")/n() * 100), no = round(sum(everPellEligibleInd == "N")/n()*100))
```

```{r enrollment}
enrollmentStatus <- SLCCpersistenceProc %>% 
  distinct(id, .keep_all = TRUE) %>% 
  summarise(FullTime = round(sum(fullTime == "Full-Time")/n() * 100), 
            PartTime = round(sum(fullTime == "Part-Time")/n() * 100))
```

```{r firstGen}
firstGen <- SLCCpersistenceProc %>%
  distinct(id, .keep_all = TRUE) %>%
  summarise(yes = round(sum(firstGenerationInd == "Y")/n() * 100), 
            no = round(sum(firstGenerationInd == "N")/n() * 100),
            unReported = round(sum(firstGenerationInd == "U")/n() * 100))
```

```{r ethnicity}
# SLCCpersistenceProc %>%
#   distinct(id, .keep_all = TRUE) %>% 
#   count(ethnicity) %>% 
#   mutate(percRace = round(n / sum(n) * 100)) %>% 
#   ggplot(aes(x = reorder(ethnicity, percRace), y = percRace)) +
#     geom_col() +  + coord_flip() + 
#     labs(x = "Ethnicity", y = "Percentage of Students") 
```

The SLCC dataset included `r n_distinct(SLCCpersistenceProc$id)` students (female =`r gender$gender[1]`, male = `r gender$gender[2]`, unreported = `r gender$gender[3]`). Out of these students, `r pell$yes`\\% were pell eligible, `r enrollmentStatus$FullTime`\\% were in full-time programs, and `r firstGen$yes`\\% identified as first generation students. 

```{r demoUgGPA, include = FALSE}
## Computing a model to see if the demographic variables determine undergradauite GPA
mod00 <- lm(cumUgGpa ~ age + ethnicity + gender + everPellEligibleInd + firstGenerationInd, data = SLCCpersistenceProc)
```

```{r UG GPA differences across Subject and instructors, include = FALSE}
mod01 <- lm(cumUgGpa ~ courseSubject + instructorId, data = SLCCpersistenceProc)
```


```{r ethnicity based differences in UG GPA, include=FALSE}
SLCCpersistenceProc %>%
  ggplot(aes(x = ethnicity, y = cumUgGpa)) +
  geom_boxplot() + # +
  labs(x = "Ethnicity", y = "Course Grade")
```

# Results

We examined the impact of OER adoption in terms of student success in the course. Student success was determined based on whether a student achieved "C-" or better in the course. If a student achieved a "C-" or better, then the student was considered to have passed (1) the class, whereas, if a student received a grade lower than a "C-", s/he was considered to have failed (0) the class. We also converted the student grades into a continuous measure that corresponded to the grade point (0-4) for the course.

```{r prepostOER, caption = "Change in mean percentage of passing students before and after introduction of OER.", cache=TRUE}
SLCCpersistenceProc %>% 
  group_by(oer, courseSubject) %>% 
  filter(courseSubject == "HIST") %>% 
  summarise(meanPerc = round(sum(pass)/n() * 100), groupSize = n()) %>% 
  ggplot(aes(x = factor(oer), y = meanPerc)) + 
    geom_col(position = "dodge", fill = "grey70") + geom_text(aes(label = groupSize)) + labs(y = "% of Passing Students", x = "OER") # +
```

```{r oerSemSinceImplementation, caption = "Change in the mean percentage of passing students since implementation of the OER.", cache=TRUE, include = FALSE}
SLCCpersistenceProc %>% 
  group_by(oer, courseSubject, semSinceImplementation) %>% 
  summarise(meanPerc = round(sum(pass)/n() * 100), groupSize = n()) %>% 
  ggplot(aes(x = factor(semSinceImplementation), y = meanPerc)) + 
  geom_col() +  + facet_wrap(~courseSubject, scales = "free_x") + 
  labs(x = "Semester since implementation of OER", y = "Mean percentage of passing students")
```


```{r prepostOERgrade, caption = "Change in mean grade of students before and after introduction of OER.", cache=TRUE, include = FALSE}
SLCCpersistenceProc %>% 
  group_by(oer, courseSubject) %>% 
  summarise(meanGrade = mean(courseGrade, na.rm = TRUE), 
            semGrade = round(sd(courseGrade, na.rm=TRUE)/sqrt(sum(!is.na(courseGrade))), 2), 
            groupSize = sum(!is.na(courseGrade))) %>% 
  ggplot(aes(x = oer, y = meanGrade, fill = courseSubject)) + 
  geom_col(position = "dodge") +  scale_fill_manual(values = osColorPalette) + #  +
  geom_errorbar(aes(ymin = meanGrade - semGrade, ymax = meanGrade + semGrade), width = .1, position = position_dodge(.9)) + ylim(c(0,4)) + 
  labs(fill = "Subject", y = "Mean Student Grade", x = "OER")
```

```{r oerSemSinceImplementationGrade, caption = "Change in the mean percentage of passing students since implementation of the OER.", cache=TRUE, include = FALSE}
SLCCpersistenceProc %>% 
  group_by(oer, courseSubject, semSinceImplementation) %>% 
  summarise(meanGrade = round(mean(courseGrade, na.rm = TRUE)), 
            semGrade = round(sd(courseGrade, na.rm=TRUE)/sqrt(sum(!is.na(courseGrade))), 2), 
            groupSize = sum(!is.na(courseGrade))) %>% 
  ggplot(aes(x = factor(semSinceImplementation), y = meanGrade)) + 
  geom_col(position = "dodge") + scale_fill_manual(values = osColorPalette) + #+ 
  geom_errorbar(aes(ymin = meanGrade - semGrade, ymax = meanGrade + semGrade), width = .1, position = position_dodge(.9)) + ylim(c(0,4)) + facet_wrap(~courseSubject, scales = "free_x") +
  labs(y = "Mean Student Grade", x = "Semester Since OER Implementation")
```


### Impact on pass rates

For the binary pass variable, we computed binomial logistic mixed effect regression models, with student, and instructor as random effects, and the pass variable as the outcome. 

In addition to a baseline model that only included the random effects, we computed 3 additive models, and one interactive model that progressively included:    

* demographic factors (age, gender, ethnicity, pell eligibility, enrollment status, first generation college student) 
* course discipline and prior performance related metrics (course subject, cumulative undergraduate GPA) 
* treatment variables (OER, semester since implementation)

We compared the AIC values and selected the model with the lowest AIC value as our winning model. We also compared our winning model against our baseline model to ensure that these were significantly different.

```{r passRate, cache=TRUE}
## Baseline model including only random effects
passMod0Base <- SLCCpersistenceProc %>% 
     glmer(pass ~ (1|instructorId), data = ., family = binomial)
```

```{r pass Additive Models, cache=TRUE}
## Mod1: Random effects + demographics
passMod1Add <- SLCCpersistenceProc %>% 
  glmer(pass ~ (1|id) + (1|instructorId) + age + ethnicity + gender + fullTime + everPellEligibleInd + firstGenerationInd, data = ., family = binomial)

## Mod2: Random effects + Demographics + subject/performance related factors
passMod2Add <- SLCCpersistenceProc %>% 
  glmer(pass ~ (1|id) + (1|instructorId) + age + ethnicity + gender + fullTime + courseSubject + cumUgGpa + everPellEligibleInd + firstGenerationInd + semester, data = ., family = binomial)

## Mod3: Random effects + Demographics + subject/performance related factors + treatment
passMod3Add <- SLCCpersistenceProc %>% 
  glmer(pass ~ (1|instructorId) + age + ethnicity + gender + fullTime + courseSubject + cumUgGpa + everPellEligibleInd + semester + oer + semSinceImplementation + firstGenerationInd, data = ., family = binomial)
```


```{r pass Omnibus Model Interactive, cache=TRUE}
## Mod4: Random effects + Demographics + subject/performance related factors + treatment + interaction terms
passMod4Int <- SLCCpersistenceProc %>% 
  glmer(pass ~ (1|instructorId) + age + gender + firstGenerationInd + fullTime + courseSubject + cumUgGpa + ethnicity + everPellEligibleInd + semester + oer + semSinceImplementation + oer:ethnicity + oer:everPellEligibleInd, data = ., family = binomial)
```

#### Model comparison   

```{r pass AIC, cache=TRUE}
AIC(passMod0, passMod1Add, passMod2Add, passMod3Add, passMod4Int)
```

```{r pass Model Comparison, cache=TRUE}
## Compare base with additive model
passComp1 <- anova(passMod0, passMod1Add)

## Compare base with interactive model
passComp2 <- anova(passMod0, passMod2Add)

## Compare additive with interactive model
passComp3 <- anova(passModOmnibusAdd, passModOmnibusInt)
```

### Impact on course grade

```{r Grade Base Model, cache=TRUE}
## Baseline model including only random effects
gradeMod0Base <- SLCCpersistenceProc %>% 
     lmer(courseGrade ~ (1|id) + (1|instructorId), data = .)
```

```{r Grade Additive Omnibus Model, cache=TRUE}
## Mod1: Random effects + demographics
gradeMod1Add <- SLCCpersistenceProc %>% 
  lmer(pass ~ (1|id) + (1|instructorId) + age + ethnicity + gender + fullTime + everPellEligibleInd + firstGenerationInd, data = .)

## Mod2: Random effects + Demographics + subject/performance related factors
gradeMod2Add <- SLCCpersistenceProc %>% 
  lmer(pass ~ (1|id) + (1|instructorId) + age + ethnicity + gender + fullTime + courseSubject + cumUgGpa + everPellEligibleInd + firstGenerationInd + semester, data = .)

## Mod2: Random effects + Demographics + subject/performance related factors + treatment
gradeMod3Add <- SLCCpersistenceProc %>% 
  lmer(pass ~ (1|id) + (1|instructorId) + age + ethnicity + gender + fullTime + semester + courseSubject + cumUgGpa + everPellEligibleInd + oer + semSinceImplementation + firstGenerationInd, data = .)
```

```{r Grade Omnibus Model Interactive, cache=TRUE}
## Mod4: Random effects + Demographics + subject/performance related factors + treatment + interaction terms
gradeMod4Int <- SLCCpersistenceProc %>% 
  lmer(pass ~ (1|id) + (1|instructorId) + age + gender + firstGenerationInd + fullTime + courseSubject + semester + oer + ethnicity + everPellEligibleInd + semSinceImplementation + oer:ethnicity + oer:everPellEligibleInd + oer:semSinceImplementation, data = .)
```

#### Model comparison   

```{r course AIC}
AIC(courseMod0, courseModOmnibusAdd, courseModOmnibusInt)
```

```{r course Model Comparison}
## Compare base with additive model
courseComp1 <- anova(courseMod0, courseModOmnibusAdd)

## Compare base with interactive model
courseComp2 <- anova(courseMod0, courseModOmnibusInt)

## Compare additive with interactive model
courseComp3 <- anova(courseModOmnibusAdd, courseModOmnibusInt)
```

## Impact on Drop/Failure/Withdrawal Rate

```{r dfwRateBase, cache=TRUE}
## Baseline model including only random effects
dfwMod0Base <- SLCCpersistenceProc %>% 
     glmer(dfw ~ (1|academicYear) + (1|semester) + (1|courseSubject/instructorId), data = ., family = binomial)
sjp.glmer(dfwMod0Base, facet.grid = TRUE)
```

```{r}
# dfwMod0Base1 <- SLCCpersistenceProc %>% 
#      glmer(dfw ~ (1|academicYear) * (1|semester) + (1|courseSubject/instructorId), data = ., family = binomial)
# sjp.glmer(dfwMod0Base1)
```


```{r dfw Additive Models, cache=TRUE}
## Mod1: Random effects + demographics
dfwMod1Add <- SLCCpersistenceProc %>% 
  glmer(dfw ~ (1|academicYear) + (1|semester) + (1|courseSubject/instructorId) + age + ethnicity + gender + fullTime + everPellEligibleInd + firstGenerationInd, data = ., family = binomial)

## Mod2: Random effects + Demographics + subject/performance related factors
dfwMod2Add <- SLCCpersistenceProc %>% 
  glmer(dfw ~ (1|academicYear) + (1|semester) + (1|courseSubject/instructorId) + age + ethnicity + gender + fullTime + cumUgGpa + everPellEligibleInd + firstGenerationInd, data = ., family = binomial)

## Mod3: Random effects + Demographics + subject/performance related factors + treatment
dfwMod3Add <- SLCCpersistenceProc %>% 
  glmer(dfw ~ (1|academicYear) + (1|semester) + (1|courseSubject/instructorId) + age + ethnicity + gender + fullTime + cumUgGpa + everPellEligibleInd + oer + semSinceImplementation + firstGenerationInd, data = ., family = binomial)
```

```{r dfw Omnibus Model Interactive, cache=TRUE}
## Mod4: Random effects + Demographics + subject/performance related factors + treatment + interaction terms
dfwMod4Int <- SLCCpersistenceProc %>% 
  glmer(dfw ~ (1|academicYear) + (1|semester) + (1|courseSubject/instructorId) + age + gender + firstGenerationInd + fullTime + cumUgGpa + ethnicity + everPellEligibleInd + semester + oer + semSinceImplementation + oer:ethnicity + oer:everPellEligibleInd + oer:semSinceImplementation, data = ., family = binomial)
```

#### Model comparison   

```{r dfw AIC, cache=TRUE}
AIC(dfwMod0Base, dfwMod1Add, dfwMod2Add, dfwMod3Add, dfwMod4Int)
```

```{r dfw Model Comparison, cache=TRUE}
## Compare base with additive model
dfwComp1 <- anova(dfwMod0, dfwMod1Add)

## Compare base with interactive model
dfwComp2 <- anova(dfwMod0, dfwMod2Add)

## Compare additive with interactive model
dfwComp3 <- anova(dfwModOmnibusAdd, dfwModOmnibusInt)
```

### Descriptives

##### How many classes does each teacher teach?
```{r numClasses, include = FALSE}
SLCCpersistenceProc %>% 
  group_by(instructorId) %>% 
  distinct(termStartDate, courseNumber) %>% count() %>% View()
```

#### Basic demographics of students

```{r demographics}
SLCCDemographics <- SLCCpersistenceProc %>% 
  distinct(id, .keep_all = TRUE) %>% 
  group_by(academicYear, gender, courseSubject, ethnicity, everPellEligibleInd) %>% 
  count()

SLCCDemographics %>% 
  select(academicYear,courseSubject, everPellEligibleInd, gender, ethnicity, n) %>% 
  arrange(academicYear,courseSubject, everPellEligibleInd, gender, ethnicity) %>% 
  kable("html", col.names = c("Academic Year", "Subject", "Pell Eligible?", "Gender", "Ethnicity","Number of Students"), caption = "Demographic distribution of students") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"), full_width = FALSE,position = "left")
```



```{r Gender based enrollment over time}
## Gender based enrollment over time
SLCCDemographics %>% 
  group_by(academicYear, gender, courseSubject) %>% 
  summarise(sumEnrolled = sum(n)) %>% 
  ggplot(aes(x = courseSubject, y = sumEnrolled, fill = gender)) + geom_col() + facet_wrap(~academicYear) + 
   + scale_fill_manual(values = osColorPalette) + labs(x = "Subject", y = "Number of Students Enrolled", fill = "Gender")
```

```{r Ethnicity based enrollment over time}
## Ethnicity based enrollment over time
SLCCDemographics %>% 
  group_by(ethnicity, gender, courseSubject) %>% 
  summarise(sumEnrolled = sum(n)) %>% 
  ggplot(aes(x = courseSubject, y = sumEnrolled, fill = gender)) + geom_col() + facet_wrap(~academicYear) + 
   + scale_fill_manual(values = osColorPalette) + labs(x = "Subject", y = "Number of Students Enrolled", fill = "Gender")
```

##### Age, Gender, Pell Eligibility

```{r AgeGenderPell}
(SLCCAgeGender <- SLCCpersistenceProc %>% 
  group_by(gender, age, everPellEligibleInd) %>% 
  ggplot(aes(x = age, fill = gender)) + geom_histogram() +  + scale_fill_manual(values = osColorPalette)+ facet_wrap(~everPellEligibleInd, scales = "free_x"))
```

```{r demographic table, echo = FALSE}
## Create a demographic table
SLCCpersistenceProc %>% 
  count(age) %>% 
  kable("html", col.names = c("Age", "Number of Students"), caption = "Agewise distribution of students") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"), full_width = FALSE, position = "left") %>% 
  row_spec(0, bold = TRUE) 
```

```{r Annual fluctuations in grade, include=FALSE}
#### SEASONAL FLUCTUATIONS #####
#courseSubject == "ECON" & 
SLCCpersistenceProc %>% 
  group_by(academicYear, courseSubject) %>% 
  count(roundedGrade) %>% 
  group_by(academicYear, courseSubject, roundedGrade) %>% 
  summarise(numCases = sum(n)) %>% 
  arrange(courseSubject, roundedGrade) %>% 
  #filter(roundedGrade == "B") %>% 
  ggplot(aes(x = academicYear, y = numCases, fill = roundedGrade)) + geom_col() + facet_wrap(~courseSubject) + labs(fill = "Grade", y = "Number of Students", x = "Academic Year") +
  scale_fill_manual(values = osColorPalette) # +
  # scale_x_date(date_breaks = "4 month", date_labels = "%b %y")
```

```{r include=FALSE}
## Enrollment: How many students in each course in each semester?
SLCCpersistenceProc %>% 
  group_by(academicYear) %>% 
  count(courseSubject) %>% 
  ggplot(aes(x = academicYear, y = n), colour = academicYear) + geom_col(position = "dodge") +
  facet_wrap(~courseSubject) +  + # geom_line() + geom_point() +
  scale_colour_manual(values = osColorPalette) + labs(y = "Number of Students Enrolled", x = "Academic Year") + geom_vline(xintercept = 2014, lty = 2, lwd = 0.2)

  
## Are there yearly fluctions in grades?

## Are there semesterly fluctuations in grades?
```

```{r withdrawalRate}
SLCCpersistenceProc %>% 
  group_by(courseSubject, courseNumber, instructorId, academicYear) %>% 
  summarise(`withdrawal/dropRate` = round(sum(finalGrade == "I")/n(), 4)) %>% View()
```

```{r withdrawalFailure}
SLCCPersistenceSFW <- SLCCpersistenceProc %>% 
  mutate(roundedGrade = gsub("\\+|\\-","", finalGrade)) %>% 
  group_by(courseSubject, courseNumber, instructorId, termStartDate, yrSem, academicYear, oer) %>% 
  summarise(success = round(sum(roundedGrade <= "C")/n(), 2), failure = round(sum(roundedGrade > "C" & roundedGrade != "I")/n(),2),  `withdrawal/dropRate` = round(sum(finalGrade == "I")/n(), 4), numStudents = n()) %>% 
  arrange(courseSubject, instructorId, termStartDate)
SLCCPersistenceSFW %>% 
  ggplot(aes(x = academicYear, y = success, color = factor(oer), group = instructorId)) + facet_wrap(~courseSubject) +    + geom_line() + geom_point() + scale_colour_manual(values = osColorPalette) + 
  labs(y = "Success Rate", x = "Academic Year", colour = "OER") #+ geom_vline(aes(xintercept = 2014), lty = 2, lwd = 0.2)
```

```{r yF, fig.width=12}
## Summarise success/failure/drop/Withdrawal rates
SLCCPersistenceSFWSummary <- SLCCPersistenceSFW %>% 
  group_by(courseSubject, yrSem, oer) %>% 
  summarise(meanSuccessRate = mean(success), meanFailureRate = mean(failure), meanWDRate = mean(`withdrawal/dropRate`), meanNumStudents = round(mean(numStudents))) 

## Plot success rates
SLCCPersistenceSFWSummary %>% 
  ggplot(aes(x = yrSem, y = meanSuccessRate, colour = factor(oer))) + facet_wrap(~courseSubject) +  + geom_point() + geom_line(aes(x = yrSem, y = meanFailureRate), lty = 2) + labs(y = "Success", x = "Academic Year") + scale_colour_manual(values = osColorPalette) # + geom_vline(aes(xintercept = '2014 Summer'), lty = 2, lwd = 0.2)
```

```{r syF}
## Plot failure rate by semester and year
SLCCPersistenceSFW %>% 
  group_by(courseSubject, academicYear) %>% 
  summarise(`Mean success rate` = mean(success), `Mean incomplete` = mean(`withdrawal/dropRate`)) %>% 
  ggplot(aes(x = academicYear, y = `Mean success rate`)) +
  facet_wrap(~courseSubject) +  + 
  geom_line() + geom_point() + geom_line(aes(x = academicYear, y = `Mean incomplete`), lty = 2) +
  labs(y = "Success Rate", x = "Academic Year") + scale_colour_manual(values = osColorPalette)
```


```{r omnibusModel, include = FALSE}
## Modify year to academic year
# mod4 <- SLCCpersistenceProc %>% 
#   glmer(pass ~ (1|id) + (1|instructorId) + oer + age + gender + everPellEligibleInd + fullTime + courseSubject + academicYear, data = ., family = binomial, nAGQ = 1, control = glmerControl(check.nobs.vs.nlev = 'ignore', check.nobs.vs.nRE = 'ignore'))
```


```{r include=FALSE}
### Time series modeling

# tmp <- SLCCpersistenceProc %>% 
#   select(termStartDate, cumUgGpa) %>% 
#   dplyr::rename(ds = termStartDate, y = cumUgGpa) %>% 
#   prophet::prophet()
# future <- make_future_dataframe(tmp, periods = 365, freq = "month")

# forecast <- predict(tmp, future)
# 
# plot_forecast_component(fcst = forecast, name = "seasonal")
# 
# tmp <- SLCCpersistenceProc %>% 
#   select(termStartDate, cumUgGpa) %>% 
#   dplyr::rename(ds = termStartDate, y = cumUgGpa) %>% 
#   prophet::prophet()
# future <- make_future_dataframe(tmp, periods = 365, freq = "month")

# forecast <- predict(tmp, future)
# 
# plot_forecast_component(fcst = forecast, name = "seasonal")
# 
# tmp <- SLCCpersistenceProc %>% 
#   select(termStartDate, cumUgGpa) %>% 
#   dplyr::rename(ds = termStartDate, y = cumUgGpa) %>% 
#   prophet::prophet()
# future <- make_future_dataframe(tmp, periods = 365, freq = "month")
# 
# forecast <- predict(tmp, future)

# plot_forecast_component(fcst = forecast, name = "seasonal")
#   
# tmp1 <- SLCCpersistenceProc %>% 
#   select(termStartDate, cumUgGpa, oer) %>% 
#   dplyr::rename(ds = termStartDate, y = cumUgGpa) %>% 
#   prophet::prophet(growth = "logistic")
# future <- make_future_dataframe(tmp, periods = 365, freq = "month")
# 
# forecast <- predict(tmp, future)
# 
# plot_forecast_component(fcst = forecast, name = "seasonal")

```

```{r ACF, include = FALSE}
# SLCCpersistenceProc %>% 
#   count(termStartDate, termEndDate) %>% View()
# SLCCts <- SLCCpersistenceProc %>% 
#   group_by(instructorId) %>% 
#   arrange(termStartDate) %>% 
#   select(cumUgGpa, courseGrade) %>% 
#   ts()
  # ts(SLCCpersistenceProc[ ,c("cumUgGpa","finalGrade")], start = SLCCpersistenceProc$termStartDate, end = SLCCpersistenceProc$termEndDate)
  
```
