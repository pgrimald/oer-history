---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
library("papaja")
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

```{r setup, echo=FALSE, warning=FALSE, message=FALSE, comment=""}
# Source supporting files
source("~/Documents/oer-history/supportingScripts/descriptives.R")
```


  A major problem currently facing education in America is the rising cost of obtaining a college degree. While tuition hikes predominate student costs, an additional source of expense is from textbook prices that have been found to rise at an alarming rate (134% increase since 2001; U.S. Bureau of Labor Statistics, 2016). Based on the Bureau of Labor statistics' estimates of average textbook costs up until May of 2018, college textbook prices have gone up by 43% since 2010 (BLS, 2018) without any seasonal adjustments. The Florida Virtual Campus survey (2016) of over 22,000 students reported that exorbitant textbook costs often determine students' academic decisions including whether they will purchase a textbook (67%), enroll in fewer class (~48%), drop (~26%) or withdraw (~21%) from a class, earn a poor grade because they were unable to buy a book (~38%).

  In order to alleviate the financial burdens exerted on students by the high textbook costs, educators and institutions are more and more invested in In response to rising textbook costs, there has been a surge of interest in open educational resources (OER). OER differs from traditional education materials in that they are freely available. While OER has undoubtedly been successful at reducing student costs, the critical question is whether these cost savings translate into improved student academic outcomes. OER is presumed to help in this regard by improving access to beneficial learning materials, however research in this area is has found equivocal results (Hilton, 2016). 
  
  Previous studies have examined the impact of OER adoption on measures of academic outcomes such as a drop, failure, withdrawal rates [@Colvard2018; Hilton2016]. 
  While some studies found that adoption of open textbooks resulted in positive academic outcomes (Colvard & Watson, 2018; Lovett et al., 2008), others have found no effect (Hilton et al., 2013), or a negative effect (Lawrence & Lester, 2018). The overarching goal of this project is to explore how adoption of an open textbook affects student academic outcomes.

  We examined the effect of transitioning from a conventional textbook to an open textbook for all sections of a required introductory history course at the Salt Lake Community College (SLCC). This was a unique opportunity to examine the impact of open textbook use because this large scale adoption was institutionally mandated, which implied that, unlike other situations where instructors generally opt in to adopt an open textbook for their own course, all instructors were required to use the same textbook for the course removing any concerns of self-selection bias. In collaboration with SLCC, we acquired student academic outcomes before and after transition to the open textbook, demographic variables, prior achievement, and other parameters related to the course. In order to account for changes in academic outcomes due to open textbook adoption, we need to control for all other parameters that might impact the course outcome.
  
  
  Previous studies have shown that academic outcomes are influenced by the financial condition of the students as 
  
  In order to ensure that changes in the academic outcomes were primarily due to open textbook adoption and not other temporal confounds, we contrasted academic outcomes in the history course with other comparable social science disciplines, which continued to exclusively use traditional textbooks during the same period.

  Preliminary results indicate that there was no positive effect of open textbook adoption on the number of students passing the course. Further analyses are underway, and the findings will be discussed in light of expectations surrounding OER efficacy, and integration of OER into a course curriculum.

# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants

## Material

## Procedure

## Data analysis
We used `r cite_r("r-references.bib")` for all our analyses.


# Results

The primary goal of this project was to examine the impact of adopting an open textbook on academic outcomes of students. SLCC adopted an open textbook for their introductory history course. In order to examine the impact that open textbook adoption had on academic outcomes, not only did we compare the academic outcomes in history before and after the adoption, we also examined academic outcomes in other social sciences disciplines at SLCC, such as economics and political science. Examining academic outcomes in other social sciences disciplines during the same period of time allowed us to investigate whether there were any periodic changes across other social sciences disciplines in general that could not be attributed to adoption of an open textbook.

We used course completion, pass rate, and average grade as indices of academic outcomes. Previous studies have often combined drop, failure, and withdrawals as a metric of academic outcome [@Colvard2018; ADD OTHER REFS]. However, we wanted to frame our research questions using parameters such as course completion, and pass rates separately so that we could examine if there were any differential impacts of open textbook adoption on these parameters. It is possible that having access to the textbook without any financial liability encourages students to complete the course. However, unless the quality of an open textbook is equal to or better than traditional textbooks, pass rates might suffer. Therefore, it allows us to make nuanced inferences than using a combined drop, failure, withdrawal metric. 

Out of the `r nrow(SLCC_11_18_proc)` student records, all but `r sum(SLCC_11_18_proc$finalGrade == "I")` case completed their respective courses. Given the course completion values were at ceiling, we did not conduct any further analyses using course completion.

We first examined the descriptives for passing, and average grade, across factors of interest followed by mixed effects hierarchical regression [@cohen2013applied] in order to estimate the impact of open textbook adoption on each outcome. This analysis is conducted by comparing two models:

- a _base model_ that contains all relevant factors that might influence the outcome except for the variable of interest (textbook type)          

- a _comparison model_ that includes the variable of interest in addition to all factors in the base model 

If the comparison model significantly outperforms the base model, then we may safely conclude that the treatment had a consequential impact on the outcome.

For examining pass rates, we conducted a logistic mixed effect hierarchical regression, in which the outcome variable was whether a single student passed (1, grade >= C-) or failed the course (0, grade < C-). The following _fixed effect_ predictor variables were included in the model:

- demographic variables such as pell eligibility, whether the students were a first generation collge goer, whether the students were registered as full-time or part-time students,          
- prior performance measure, the cumulative undergraduate GPA           
- delivery method of the course, i.e., whether the course was delivered in a traditional classroom or online        
In addition to the above fixed effect variables, the following _random effect_ variables were also included in the model:

- academic year (Fall to Summer constituting one academic year)           
- semester (Fall, Summer, Spring)                    
- instructors nested under course subject                     


```{r, include = FALSE, eval = FALSE}
ethnicityAvgGradePlt
```

## Mean grade in social science subjects that used different textbook types (traditional vs. open) across students who were (Y) and were not (N) pell eligibility

```{r pellPass, fig.width=9.5, fig.cap="Mean grade across students with differing Pell eligibility, subjects, and textbook type used. 'Y' denotes students were pell eligible, and 'N' denotes that they were not pell eligible. The error bars indicate the standard error of mean, and n indicates the number of students for each condition. Average grade is similar across pell status. However, mean grade is slightly lower for students using open textbooks."}
pellStatusAvgGradeBarPlt
```

## Mean grade in social science subjects that used different textbook types (traditional vs. open) across full-time and part-time students 

```{r regStatGrade, fig.width=9.5, fig.cap="Mean grade across students registered either as full-time or part-time students, subjects, and textbook type used. The error bars indicate the standard error of mean, and n indicates the number of students in each group. The mean grades are similar across registration status. However, mean grade is slightly lower for students using open textbooks."}
regStatusAvgGradePlt
```

## Mean grade in social science subjects that used different textbook types (traditional vs. open) across students of different pell eligibility status 

```{r firstgen, fig.width=12.5, fig.cap="Mean grade across students with differing first  status, subjects, and textbook type used. The label 'N' along the horizontal axis denotes that students were not first generation college goers, 'U' denotes unknown, and 'Y' denotes first generation students. The error bars indicate the standard error of mean, and n indicates the number of students for each condition. Average grade is similar across registration status. However, mean grade is slightly lower for students using open textbooks."}
firstGenAvgGradePlt
```

## Mean grade in social science subjects that used different textbook types (traditional vs. open) across classroom and online courses

```{r onlineGrade, fig.width=9.5, fig.cap="Mean grade across students with differing first  status, subjects, and textbook type used. The error bars indicate the standard error of mean, and n indicates the number of students for each condition. Average grade is similar across registration status. However, mean grade is slightly lower for students using open textbooks."}
avgGradeOnline
```

## Boxplot showing grades in social science subjects that used different textbook types (traditional vs. open) across different cumulative undergraduate 


```{r cumGPAGrade, fig.width=12, fig.cap=""}
gpaAvgGrade
```

```{r pass mod, results='asis'}
stargazer::stargazer(passM0, passM1, passM2, type = "latex",covariate.labels = c("Pell Eligibility","First Generation Status Unknown","First Generation Status Yes","Registration Status","Cumulative Ungraduate GPA","Course Type","Textbook Type", "Textbook Type x Pell Status", "Textbook Type x Course Type"), dep.var.labels = "Mean Grade", ci = TRUE, dep.var.caption = " ", digits = 2)
```

```{r history pass mod, results='asis'}
stargazer::stargazer(passHM0, passHM1, passHM2, type = "latex",covariate.labels = c("Pell Eligibility","First Generation Status Unknown","First Generation Status Yes","Registration Status","Cumulative Ungraduate GPA","Course Type","Textbook Type", "Textbook Type x Pell Status", "Textbook Type x Course Type"), dep.var.labels = "Mean Grade", ci = TRUE, dep.var.caption = " ", digits = 2)
```

```{r grade mod, results='asis'}
stargazer::stargazer(gradeM0, gradeM1, gradeM2, type = "latex",covariate.labels = c("Pell Eligibility","First Generation Status Unknown","First Generation Status Yes","Registration Status","Cumulative Ungraduate GPA","Course Type","Textbook Type", "Textbook Type x Pell Status", "Textbook Type x Course Type"), dep.var.labels = "Mean Grade", ci = TRUE, dep.var.caption = " ", digits = 2)
```

```{r history grade mod, results='asis'}
stargazer::stargazer(gradeHM0, gradeHM1, gradeHM2, type = "latex",covariate.labels = c("Pell Eligibility","First Generation Status Unknown","First Generation Status Yes","Registration Status","Cumulative Ungraduate GPA","Course Type","Textbook Type", "Textbook Type x Pell Status", "Textbook Type x Course Type"), dep.var.labels = "Mean Grade", ci = TRUE, dep.var.caption = " ", digits = 2)
```

## Pass rate

surmise that drops, withdrawals, and failures could be attributed to different causal factors. While drops and withdrawals may be attributed to factors such as textbook costs or other financial hardships, and course difficulty, failure could be attributed to additional factors such as not meeting course requirements (for e.g. class attendance, doing required assignments in a timely fashion), or not being able to keep up with course content. For our analyses, we decided to 


# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
